{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %pip install tensorflow-addons==0.11.2"
      ],
      "metadata": {
        "id": "y7komgzmOOcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow-gpu==2.3.0\n",
        "# if you are using cpu, just install tensorflow==2.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eee12gRFOcXT",
        "outputId": "014b7fbd-1ae8-4f45-92e1-41f644aca440"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==2.3.0\n",
            "  Downloading tensorflow_gpu-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4 MB 51 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.14.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.44.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.10.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.4.1)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
            "\u001b[K     |████████████████████████████████| 459 kB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.0.0)\n",
            "Collecting tensorboard<3,>=2.3.0\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.2.0)\n",
            "Installing collected packages: numpy, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Attempting uninstall: tensorflow-gpu\n",
            "    Found existing installation: tensorflow-gpu 2.2.0\n",
            "    Uninstalling tensorflow-gpu-2.2.0:\n",
            "      Successfully uninstalled tensorflow-gpu-2.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "tensorflow 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.9.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.8 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.18.5 tensorboard-2.9.0 tensorflow-estimator-2.3.0 tensorflow-gpu-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JqTbU-1AyjxG"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers as layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GTBVNsj1yjxM"
      },
      "outputs": [],
      "source": [
        "# params\n",
        "CLASSES_NUM = 6  # 输出6类地物\n",
        "LABELS = ['', 'Trees', 'Asphalt', 'Parking lot', 'Bitumen', 'Meadow', 'Soil']\n",
        "VAL_FRAC = 0.5\n",
        "TEST_FRAC = 0.3  # target用来测试数据的百分比 test/train\n",
        "TRAIN_FRAC = 0.7\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 70\n",
        "LAMBDA = 100\n",
        "BANDS = 72\n",
        "EPOCHS = 1000\n",
        "PATIENCE = 15\n",
        "noise_dim = 72\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([BATCH_SIZE, 72, 1])\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "FEATURE_dim = 36\n",
        "lr = 1e-4 * 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qwHZdGd_yjxN"
      },
      "outputs": [],
      "source": [
        "# utils\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "def gen_dataset_from_dict(file_dict, Val=False):\n",
        "    data = file_dict['data']\n",
        "    data = np.transpose(data, (0, 2, 1))\n",
        "    label = file_dict['gt']\n",
        "    data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=TEST_FRAC, random_state=42)\n",
        "    if Val:\n",
        "        data_test, data_val, label_test, label_val = train_test_split(data_test, label_test, test_size=VAL_FRAC,\n",
        "                                                                      random_state=43)\n",
        "    data_train = tf.data.Dataset.from_tensor_slices(data_train)\n",
        "    data_test = tf.data.Dataset.from_tensor_slices(data_test)\n",
        "    label_train = tf.data.Dataset.from_tensor_slices(label_train)\n",
        "    label_test = tf.data.Dataset.from_tensor_slices(label_test)\n",
        "    if Val:\n",
        "        data_val = tf.data.Dataset.from_tensor_slices(data_val)\n",
        "        label_val = tf.data.Dataset.from_tensor_slices(label_val)\n",
        "        val_ds = tf.data.Dataset.zip((data_val, label_val))\n",
        "        val_ds = val_ds.map(lambda x, y: {'data': x, 'label': y}).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "    train_ds = tf.data.Dataset.zip((data_train, label_train))\n",
        "    test_ds = tf.data.Dataset.zip((data_test, label_test))\n",
        "\n",
        "    train_ds = train_ds.map(lambda x, y: {'data': x, 'label': y}).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "    test_ds = test_ds.map(lambda x, y: {'data': x, 'label': y}).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "    if Val:\n",
        "        return train_ds, test_ds, val_ds\n",
        "    else:\n",
        "        return train_ds, test_ds\n",
        "\n",
        "\n",
        "def generate_and_save_Images(model, epoch, test_input):\n",
        "    \"\"\"Notice `training` is set to False.\n",
        "       This is so all layers run in inference mode (batch norm).\"\"\"\n",
        "    \"\"\"To-do: reshape the curves as they were normalized\"\"\"\n",
        "    prediction = model(test_input, training=False)\n",
        "    plt.plot(np.arange(72), prediction[0, :, 0])\n",
        "    plt.savefig('./pics/image_at_{:04d}_epoch.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_data_from_batch(batches):\n",
        "    return batches['data'], batches['label']\n",
        "\n",
        "\n",
        "def calculate_acc(target_test_ds,\n",
        "                  classifier,\n",
        "                  epoch):\n",
        "    target_batch = target_test_ds.shuffle(BUFFER_SIZE).as_numpy_iterator().next()\n",
        "    target_data, target_label = get_data_from_batch(target_batch)\n",
        "    prediction_t = classifier(target_data, training=False)\n",
        "    accuracy_t = tf.metrics.Accuracy(target_label, prediction_t)\n",
        "    acc = accuracy_t.result()\n",
        "    accuracy_t.update_state(y_true=target_label,\n",
        "                            y_pred=prediction_t)\n",
        "    print('Target accuracy for epoch {} is'.format(epoch + 1),\n",
        "          '{}%'.format(accuracy_t.result().numpy() * 100))\n",
        "    return acc\n",
        "\n",
        "\n",
        "def plot_acc_loss(acc, gen_loss, disc_loss, cls_loss,\n",
        "                  generator_loss, discriminator_loss, classifier_loss,\n",
        "                  source_test_ds, target_test_ds,\n",
        "                  generator, discriminator, classifier,\n",
        "                  epoch):\n",
        "    g_loss, d_loss, c_loss, a = [], [], [], []\n",
        "    for source_test_batch in source_test_ds.as_numpy_iterator():\n",
        "        for target_test_batch in target_test_ds.as_numpy_iterator():\n",
        "            X_s, Y_s = get_data_from_batch(source_test_batch)\n",
        "            X_t, Y_t = get_data_from_batch(target_test_batch)\n",
        "            generated_target = generator(X_s, training=False)\n",
        "            real_decision = discriminator(X_t, training=False)\n",
        "            fake_decision = discriminator(generated_target, training=False)\n",
        "            prediction = classifier(X_t, training=False)\n",
        "            accuracy_t = tf.metrics.Accuracy()\n",
        "            accuracy_t.update_state(y_true=Y_t,\n",
        "                                    y_pred=prediction)\n",
        "            a.append(accuracy_t.result().numpy())\n",
        "            c_loss.append(classifier_loss(prediction, Y_t).numpy())\n",
        "            g_loss.append(generator_loss(fake_decision).numpy())\n",
        "            d_loss.append(discriminator_loss(real_decision, fake_decision).numpy())\n",
        "    a = np.average(a)\n",
        "    acc.append(a)\n",
        "    cls_loss.append(np.average(c_loss))\n",
        "    gen_loss.append(np.average(g_loss))\n",
        "    disc_loss.append(np.average(d_loss))\n",
        "    epochs_range = range(epoch+1)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, gen_loss, label='Generator_loss')\n",
        "    plt.plot(epochs_range, disc_loss, label='Discriminator_loss')\n",
        "    plt.plot(epochs_range, cls_loss, label='Classifier_loss')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Generator and discriminator loss')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, acc, label='Test accuracy')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()\n",
        "    return acc, gen_loss, disc_loss, cls_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cyUDeV8ByjxP"
      },
      "outputs": [],
      "source": [
        "# Resnet\n",
        "class ResBlock_up_top(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_channels):\n",
        "        super().__init__()\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.unsampling = layers.UpSampling1D()\n",
        "        self.conv = tfa.layers.SpectralNormalization(layers.Conv1D(filters=output_channels,\n",
        "                                                                   kernel_size=3,\n",
        "                                                                   strides=1,\n",
        "                                                                   padding='same',\n",
        "                                                                   use_bias=False))\n",
        "        self.conv_skip = tfa.layers.SpectralNormalization(layers.Conv1D(filters=output_channels,\n",
        "                                                                        kernel_size=1,\n",
        "                                                                        strides=1,\n",
        "                                                                        padding='same',\n",
        "                                                                        use_bias=False))\n",
        "        self.relu = layers.LeakyReLU()\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        res = inputs\n",
        "        res = self.unsampling(res)\n",
        "        res = self.conv_skip(res)\n",
        "\n",
        "        x = self.bn(inputs)\n",
        "        x = self.relu(x)\n",
        "        x = self.unsampling(x)\n",
        "        x = self.conv_skip(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x + res\n",
        "\n",
        "\n",
        "class ResBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_channels):\n",
        "        super().__init__()\n",
        "        self.Conv = tfa.layers.SpectralNormalization(layers.Conv1D(filters=output_channels,\n",
        "                                                                   kernel_size=3,\n",
        "                                                                   strides=1,\n",
        "                                                                   padding='same',\n",
        "                                                                   use_bias=False))\n",
        "        self.Relu = layers.LeakyReLU()\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        res = inputs\n",
        "        x = self.Conv(inputs)\n",
        "        x = self.Relu(x)\n",
        "        x = self.Conv(x)\n",
        "        x = x + res\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResBlock_up(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_channels, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.relu = layers.LeakyReLU()\n",
        "        self.unsampling = layers.UpSampling1D()\n",
        "        self.conv = tfa.layers.SpectralNormalization(layers.Conv1D(filters=output_channels,\n",
        "                                                                   kernel_size=3,\n",
        "                                                                   strides=1,\n",
        "                                                                   padding='same',\n",
        "                                                                   use_bias=False))\n",
        "        self.conv_skip = tfa.layers.SpectralNormalization(layers.Conv1D(filters=output_channels,\n",
        "                                                                        kernel_size=1,\n",
        "                                                                        padding='same',\n",
        "                                                                        use_bias=False))\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        res = inputs\n",
        "        res = self.unsampling(res)\n",
        "        res = self.conv_skip(res)\n",
        "        x = self.bn(inputs)\n",
        "        x = self.relu(x)\n",
        "        x = self.unsampling(x)\n",
        "        x = self.conv_skip(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv(x)\n",
        "        return x + res\n",
        "\n",
        "\n",
        "class ResBlock_Down(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_channels):\n",
        "        super().__init__()\n",
        "        self.relu = layers.LeakyReLU()\n",
        "        self.conv = tfa.layers.SpectralNormalization(layers.Conv1D(filters=output_channels,\n",
        "                                                                   kernel_size=3,\n",
        "                                                                   padding='same',\n",
        "                                                                   use_bias=False))\n",
        "        self.conv_skip = tfa.layers.SpectralNormalization(layers.Conv1D(filters=output_channels,\n",
        "                                                                        kernel_size=1,\n",
        "                                                                        padding='same',\n",
        "                                                                        use_bias=False))\n",
        "        self.avg_pooling = layers.AveragePooling1D(padding='same')\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        res = self.conv_skip(inputs)\n",
        "        res = self.avg_pooling(res)\n",
        "\n",
        "        x = self.relu(inputs)\n",
        "        x = self.conv_skip(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.avg_pooling(x)\n",
        "\n",
        "        return x + res\n",
        "\n",
        "\n",
        "class Res_Dense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.dense = tfa.layers.SpectralNormalization(layers.Dense(units))\n",
        "        self.drop = layers.Dropout(0.3)\n",
        "        self.relu = layers.LeakyReLU()\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        res = inputs\n",
        "        res = self.dense(res)\n",
        "        res = self.relu(res)\n",
        "\n",
        "        x = self.dense(inputs)\n",
        "        x = self.drop(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x + res\n",
        "\n",
        "\n",
        "class bottle_neck(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_channels):\n",
        "        super().__init__()\n",
        "        self.filters = output_channels\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.conv = layers.Conv1D(filters=output_channels,\n",
        "                                  kernel_size=3,\n",
        "                                  padding='same',\n",
        "                                  use_bias=False)\n",
        "        self.conv_skip = layers.Conv1D(filters=output_channels,\n",
        "                                       kernel_size=1,\n",
        "                                       strides=1,\n",
        "                                       padding='same',\n",
        "                                       use_bias=False)\n",
        "        self.conv_trans = layers.Conv1D(filters=output_channels,\n",
        "                                                 kernel_size=1,\n",
        "                                                 strides=1,\n",
        "                                                 padding='same',\n",
        "                                                 use_bias=False)\n",
        "        self.unsampling = layers.UpSampling1D()\n",
        "        self.relu = layers.LeakyReLU()\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        if self.filters != inputs.get_shape().as_list()[-1]:\n",
        "            res = self.conv_skip(inputs)\n",
        "        else:\n",
        "            res = inputs\n",
        "        x = self.conv(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv_trans(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        z = x + res\n",
        "\n",
        "        return x + res\n",
        "\n",
        "\n",
        "class bottleneck_rev_s(layers.Layer):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.filters = channels\n",
        "        self.unit = bottle_neck(int(channels//2.0))\n",
        "        self.dense = layers.Dense(int(channels//2.0))\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x1, x2 = tf.split(inputs, 2, 2)\n",
        "        if self.filters != inputs.get_shape().as_list()[-1]:\n",
        "            x1 = self.dense(x1)\n",
        "        y1 = x1 + self.unit(x2)\n",
        "        y2 = x2\n",
        "        z = tf.concat([y2, y1], axis=2)\n",
        "        return z\n",
        "\n",
        "\n",
        "class ResBlock_no_sn(layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.dense1 = layers.Dense(units)\n",
        "        self.dense2 = layers.Dense(units)\n",
        "        self.dropout = layers.Dropout(0.3)\n",
        "        self.relu = layers.LeakyReLU()\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        res = self.dense1(inputs)\n",
        "        res = self.relu(res)\n",
        "\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        return x+res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qNC_gtieyjxS"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "def down_sample(filters, size, apply_bn=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(\n",
        "        tf.keras.layers.Conv1D(filters, size, strides=1, padding='same',\n",
        "                               kernel_initializer=initializer, use_bias=False))\n",
        "    if apply_bn:\n",
        "        result.add(tfa.layers.InstanceNormalization())\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "    return result\n",
        "\n",
        "\n",
        "def up_sample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(\n",
        "        tf.keras.layers.Conv1D(filters, size, strides=1,\n",
        "                               padding='same',\n",
        "                               kernel_initializer=initializer,\n",
        "                               use_bias=False))\n",
        "\n",
        "    result.add(tfa.layers.InstanceNormalization())\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def make_classifier_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(FEATURE_dim * 2, input_shape=(72, 1)))\n",
        "    model.add(ResBlock_up_top(FEATURE_dim))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(ResBlock_up(FEATURE_dim))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(CLASSES_NUM, activation='relu'))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(CLASSES_NUM))\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_generator():\n",
        "    inputs = tf.keras.layers.Input(shape=[72, 1])\n",
        "    down_stack = [\n",
        "        down_sample(64, 4, apply_bn=False),  # (batch_size, 128, 128, 64)\n",
        "        down_sample(128, 4),  # (batch_size, 64, 64, 128)\n",
        "        down_sample(256, 4),  # (batch_size, 32, 32, 256)\n",
        "        down_sample(512, 4),  # (batch_size, 16, 16, 512)\n",
        "        down_sample(512, 4),  # (batch_size, 8, 8, 512)\n",
        "        down_sample(512, 4),  # (batch_size, 4, 4, 512)\n",
        "        down_sample(512, 4),  # (batch_size, 2, 2, 512)\n",
        "        down_sample(512, 4),  # (batch_size, 1, 1, 512)\n",
        "    ]\n",
        "    up_stack = [\n",
        "        up_sample(512, 4, apply_dropout=True),\n",
        "        up_sample(512, 4, apply_dropout=True),\n",
        "        up_sample(512, 4, apply_dropout=True),\n",
        "        up_sample(512, 4),\n",
        "        up_sample(256, 4),\n",
        "        up_sample(128, 4),\n",
        "        up_sample(64, 4),\n",
        "    ]\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv1D(1, 4,\n",
        "                                  strides=1,\n",
        "                                  padding='same',\n",
        "                                  kernel_initializer=initializer,\n",
        "                                  activation='tanh')\n",
        "    x = inputs\n",
        "    # Downsampling through the model\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "    skips = reversed(skips[:-1])\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = tf.keras.layers.Concatenate()([x, skip])\n",
        "    x = last(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "    # Mean absolute error\n",
        "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "    return total_gen_loss, gan_loss, l1_loss\n",
        "\n",
        "\n",
        "def make_discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    inp = tf.keras.layers.Input(shape=[72, 1], name='input_spectral')\n",
        "    tar = tf.keras.layers.Input(shape=[72, 1], name='target_spectral')\n",
        "    x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n",
        "    down1 = down_sample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
        "    down2 = down_sample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
        "    down3 = down_sample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
        "\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding1D()(down3)  # (batch_size, 34, 34, 256)\n",
        "    conv = tf.keras.layers.Conv1D(512, 4, strides=1,\n",
        "                                  kernel_initializer=initializer,\n",
        "                                  use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
        "    instanceNorm = tfa.layers.InstanceNormalization()(conv)\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(instanceNorm)\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding1D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
        "    last = tf.keras.layers.Conv1D(1, 4, strides=1,\n",
        "                                  kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
        "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
        "\n",
        "\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_disc_loss\n",
        "\n",
        "\n",
        "cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "def classifier_loss(prediction, label):\n",
        "    return cat_cross_entropy(label, prediction)\n",
        "\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "classifier_optimizer = tf.keras.optimizers.Adagrad(2e-4)\n",
        "\n",
        "\n",
        "def generate_images(model, test_input, tar):\n",
        "    prediction = model(test_input, training=True)\n",
        "    # plt.figure(figsize=(15, 15))\n",
        "\n",
        "    display_list = [test_input[0], tar[0], prediction[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(2, 2, i + 1)\n",
        "        plt.title(title[i])\n",
        "        # Getting the pixel values in the [0, 1] range to plot.\n",
        "        plt.plot(np.arange(72), display_list[i])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_epoch(model, source_batch, target_batch):\n",
        "    xs, ys = get_data_from_batch(source_batch)\n",
        "    xt, yt = get_data_from_batch(target_batch)\n",
        "    for _ in range(BATCH_SIZE):\n",
        "        generate_images(model, xs, xt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XlpbpSaGyjxU"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "log_dir = \"logs/\"\n",
        "\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "    log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def generator_train_step(source_train_batch, target_train_batch,\n",
        "                         generator, discriminator,\n",
        "                         epoch):\n",
        "    xs, ys = get_data_from_batch(source_train_batch)\n",
        "    xt, yt = get_data_from_batch(target_train_batch)\n",
        "    if xs.shape == xt.shape:\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            gen_output = generator(xs, training=True)\n",
        "            disc_real_output = discriminator([xs, xt], training=True)\n",
        "            disc_generated_output = discriminator([xs, gen_output], training=True)\n",
        "\n",
        "            gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, xt)\n",
        "            disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "        generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                                generator.trainable_variables)\n",
        "        discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                                     discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                                generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                                    discriminator.trainable_variables))\n",
        "        with summary_writer.as_default():\n",
        "            tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
        "            tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
        "            tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
        "            tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
        "\n",
        "\n",
        "def classify_train_step(generator, classifier,\n",
        "                        source_batch, target_batch, epoch):\n",
        "    xs, ys = get_data_from_batch(source_batch)\n",
        "    xt, yt = get_data_from_batch(target_batch)\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction = classifier(xt, training=True)\n",
        "        classify_loss = classifier_loss(prediction, yt)\n",
        "\n",
        "        generated_target = generator(xs, training=False)\n",
        "        prediction_fake = classifier(generated_target, training=True)\n",
        "        classify_loss += classifier_loss(prediction_fake, ys)\n",
        "\n",
        "        classify_gradient = tape.gradient(classify_loss, classifier.trainable_variables)\n",
        "        classifier_optimizer.apply_gradients(zip(classify_gradient,\n",
        "                                                 classifier.trainable_variables))\n",
        "        train_accuracy = tf.keras.metrics.CategoricalAccuracy('train_accuracy')\n",
        "        with summary_writer.as_default():\n",
        "            tf.summary.scalar('gen_total_loss', classify_loss, step=epoch)\n",
        "            tf.summary.scalar('gen_gan_acc', train_accuracy.result(), step=epoch)\n",
        "\n",
        "\n",
        "def fit(source_train_ds, target_train_ds,\n",
        "        generator, discriminator,\n",
        "        classifier,\n",
        "        epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        # early stopping is not recommended in GAN!!!\n",
        "        for source_batch in source_train_ds.as_numpy_iterator():\n",
        "            for target_batch in target_train_ds.as_numpy_iterator():\n",
        "                generator_train_step(source_batch, target_batch,\n",
        "                                     generator, discriminator, epochs)\n",
        "        print('Time for epoch {} is {:.2f} sec'.format(epoch+1, time.time()-start))\n",
        "    patience = PATIENCE\n",
        "    wait = 0\n",
        "    best = 0\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        for source_batch in source_train_ds.as_numpy_iterator():\n",
        "            for target_batch in target_train_ds.as_numpy_iterator():\n",
        "                classify_train_step(generator, classifier,\n",
        "                                    source_batch, target_batch, epoch)\n",
        "        acc = calculate_acc(target_train_ds, classifier, epoch)\n",
        "        print(acc)\n",
        "        print(f'Time taken for epoch {epoch + 1} is:{time.time() - start:.2f} sec\\n')\n",
        "        if epoch > EPOCHS * 0.5:\n",
        "            wait += 1\n",
        "            if acc > best:\n",
        "                best = acc\n",
        "                wait = 0\n",
        "            if wait >= patience:\n",
        "                break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Btxs-3EkyjxV",
        "outputId": "456a7232-b639-4a08-aaee-b48ae5f685fe"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 157.10 sec\n",
            "Time for epoch 2 is 150.49 sec\n",
            "Time for epoch 3 is 150.98 sec\n",
            "Time for epoch 4 is 150.84 sec\n",
            "Time for epoch 5 is 150.78 sec\n",
            "Time for epoch 6 is 150.89 sec\n",
            "Time for epoch 7 is 151.01 sec\n",
            "Time for epoch 8 is 151.24 sec\n",
            "Time for epoch 9 is 151.29 sec\n",
            "Time for epoch 10 is 151.15 sec\n",
            "Time for epoch 11 is 150.84 sec\n",
            "Time for epoch 12 is 150.69 sec\n",
            "Time for epoch 13 is 150.83 sec\n",
            "Time for epoch 14 is 151.00 sec\n",
            "Time for epoch 15 is 151.07 sec\n",
            "Time for epoch 16 is 151.12 sec\n",
            "Time for epoch 17 is 151.03 sec\n",
            "Time for epoch 18 is 150.65 sec\n",
            "Time for epoch 19 is 150.54 sec\n",
            "Time for epoch 20 is 150.62 sec\n",
            "Time for epoch 21 is 150.79 sec\n",
            "Time for epoch 22 is 150.69 sec\n",
            "Time for epoch 23 is 150.95 sec\n",
            "Time for epoch 24 is 150.75 sec\n",
            "Time for epoch 25 is 151.07 sec\n",
            "Time for epoch 26 is 150.98 sec\n",
            "Time for epoch 27 is 150.96 sec\n",
            "Time for epoch 28 is 150.95 sec\n",
            "Time for epoch 29 is 150.87 sec\n",
            "Time for epoch 30 is 150.64 sec\n",
            "Time for epoch 31 is 151.01 sec\n",
            "Time for epoch 32 is 150.62 sec\n",
            "Time for epoch 33 is 150.80 sec\n",
            "Time for epoch 34 is 150.89 sec\n",
            "Time for epoch 35 is 150.67 sec\n",
            "Time for epoch 36 is 151.03 sec\n",
            "Time for epoch 37 is 150.88 sec\n",
            "Time for epoch 38 is 151.06 sec\n",
            "Time for epoch 39 is 150.71 sec\n",
            "Time for epoch 40 is 151.04 sec\n",
            "Time for epoch 41 is 150.75 sec\n",
            "Time for epoch 42 is 150.77 sec\n",
            "Time for epoch 43 is 150.86 sec\n",
            "Time for epoch 44 is 150.59 sec\n",
            "Time for epoch 45 is 150.57 sec\n",
            "Time for epoch 46 is 150.82 sec\n",
            "Time for epoch 47 is 150.50 sec\n",
            "Time for epoch 48 is 150.78 sec\n",
            "Time for epoch 49 is 150.47 sec\n",
            "Time for epoch 50 is 150.65 sec\n",
            "Time for epoch 51 is 150.70 sec\n",
            "Time for epoch 52 is 150.75 sec\n",
            "Time for epoch 53 is 150.83 sec\n",
            "Time for epoch 54 is 150.89 sec\n",
            "Time for epoch 55 is 150.72 sec\n",
            "Time for epoch 56 is 150.77 sec\n",
            "Time for epoch 57 is 150.67 sec\n",
            "Time for epoch 58 is 150.78 sec\n",
            "Time for epoch 59 is 150.87 sec\n",
            "Time for epoch 60 is 150.81 sec\n",
            "Time for epoch 61 is 150.96 sec\n",
            "Time for epoch 62 is 150.89 sec\n",
            "Time for epoch 63 is 150.66 sec\n",
            "Time for epoch 64 is 150.50 sec\n",
            "Time for epoch 65 is 150.46 sec\n",
            "Time for epoch 66 is 150.51 sec\n",
            "Time for epoch 67 is 150.57 sec\n",
            "Time for epoch 68 is 150.77 sec\n",
            "Time for epoch 69 is 150.89 sec\n",
            "Time for epoch 70 is 151.03 sec\n",
            "Time for epoch 71 is 150.80 sec\n",
            "Time for epoch 72 is 150.71 sec\n",
            "Time for epoch 73 is 150.95 sec\n",
            "Time for epoch 74 is 150.93 sec\n",
            "Time for epoch 75 is 150.57 sec\n",
            "Time for epoch 76 is 150.81 sec\n",
            "Time for epoch 77 is 150.59 sec\n",
            "Time for epoch 78 is 150.92 sec\n",
            "Time for epoch 79 is 151.09 sec\n",
            "Time for epoch 80 is 150.52 sec\n",
            "Time for epoch 81 is 150.57 sec\n"
          ]
        }
      ],
      "source": [
        "# main\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\"\"\"load data\"\"\"\n",
        "source_dict = sio.loadmat('/content/Source.mat')\n",
        "source_train_ds, source_test_ds = gen_dataset_from_dict(source_dict)\n",
        "target_dict = sio.loadmat('/content/Target.mat')\n",
        "target_train_ds, target_test_ds, target_val_ds = gen_dataset_from_dict(target_dict, Val=True)\n",
        "\n",
        "plt.plot(np.arange(72), source_train_ds.as_numpy_iterator().next()['data'][0, :, 0])\n",
        "plt.title('Source')\n",
        "plt.show()\n",
        "\n",
        "generator = make_generator()\n",
        "discriminator = make_discriminator()\n",
        "classifier = make_classifier_model()\n",
        "fit(source_train_ds, target_train_ds,\n",
        "    generator, discriminator, classifier, EPOCHS)\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy('val_accuracy')\n",
        "acc = []\n",
        "for val_batch in target_val_ds.as_numpy_iterator():\n",
        "    x, y = get_data_from_batch(val_batch)\n",
        "    prediction = classifier(x, training=False)\n",
        "    val_accuracy(y, prediction)\n",
        "    acc.append(val_accuracy.result()*100)\n",
        "    template = 'average Accuracy: {:.2f}%'\n",
        "    print(template.format(np.average(acc)))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "cycleGAN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}